---
layout: post
title:  "How to build an Anvi'o Phylogenomics Database!"
date:   2018-06-18
excerpt: "Do what pplacer does but slower and dumber. But.... accurately."
---


### v 0.1.0

Hello there! This is the first iteration of a tutorial on how to use my phylogenomics pipeline (powered by Anvi'o and ITOL).

First, let's address a key question: why would you want to do this?

  - You have an insatiable desire to create phylogenetic trees
  - You have some unknown genomes that you want to get a taxonomic placement for
  - You want to pull out ribosomal genes from lots of genomes at once
  - You want to experience sassy error messages from Anvi'o

If any of those apply to you, read on! If not... do what you like, I suppose.

Please note that the following tutorial only applies to Unix-based systems. If you don't have a Unix-based system, consider getting one.

---

## Installation

There are two possible situations if you're reading this.

1. You are working at Pitt and have access to Microbiome01.

2. You don't have access to the Pitt cluster.

If the first one applies to you, either use my account or talk to Kelvin. (Emailing me would be preferable in this case if it's not running globally yet; I can give you the info you need to run this)

If the second one applies to you, we're going to do some installation.

If you don't have Python installed, go ahead and install that (instructions are distribution-specific, and I leave it in your capable hands).

First, go [here](https://www.anaconda.com/download/#linux) to download the Anaconda installer. Please ensure you download the version that fits the Python version you have.

Second, go to wherever you downloaded the file and perform the following:

```
  $ bash Anaconda[VERSION NAME].sh
```

Then follow the helpful instructions. The wonderful thing about Anaconda is that this will work fine even if you're on a cluster where you don't have sudo access. Trying to install software without sudo can be aggravating, and conda tends to get past that particular hurdle very well.

This will create a local installation; if you're on a cluster with multiple users, this will not give them access to it!! In order to do so you will likely have to do a couple things, like:

 - modify the conda directory (which you will specify upon install) to be accessible to all users if necessary.
 - Take the line generated by conda in your .bashrc (in your home directory; try using 'ls -a' to find it) and have other users put it in their .bashrc files.

Congratulations! From this point on installing things should be easy. Make sure you can run conda:

```
  $ conda --version
```

If everything's good, proceed. Otherwise... try again or contact me with your error. Google is also a reliable friend in instances like these, and you will likely be able to solve this most quickly by googling it. Please try that before contacting me or I will tell you to google it.

### Installing Anvi'o
Watch this.

```
conda create -n anvio4 -c bioconda -c conda-forge python=3 anvio=4
```

Boom.

### Installing iqtree

And again, bask in the glory of easy software installation.

```
  $ conda install -c bioconda iqtree
```

Ta-dah!


---

## Basic overview and outline

The phylogenomics workflow I've "developed" (I put together other people's software; this is just how to do it) is fairly straightforward, though it does involve a couple of steps.
The main purpose behind it was to create a database to use to generate taxonomic placements for unknown MAGs from a sample of Sage Grouse secum. We got several MAGs out of my assembly pipeline ([https://github.com/jwestrob/Metaxas](https://github.com/jwestrob/Metaxas); if you're trying to use this please let me know so I can help) but had no way of doing taxonomic ID for any of them, save for one _Megamonas_ MAG.

Essentially, Anvi'o has several suites of HMMs for bacterial and archaeal single-copy genes, as well as ribosomal RNA genes. The basic gist of what I do here is covered in great detail here as well: [http://merenlab.org/2017/06/07/phylogenomics/](http://merenlab.org/2017/06/07/phylogenomics/) I highly recommend you look there for a good understanding of all the things Anvi'o can do, as well as bash tips and tricks. The folks at the Meren lab know exactly what they're doing.

This is kind of a stripped-down, streamlined version of what that page describes, with examples of how to go about adding to the database and understanding what it is and does.

---

Please note that I have made several scripts to make this process a lot easier. I'm going to show you precisely how to go about using them with a specific tutorial (TODO: ADD LINK TO EXAMPLE DOC).

The scripts are hosted at https://github.com/jwestrob/Script_Toybox. If you are going to proceed with the tutorial, please clone this repository onto your computer as so:

```
git clone https://github.com/jwestrob/Script_Toybox.git
```

From here on out, I will refer to the directory where you placed this repository as "SCRIPTS". I recommend putting it someplace convenient, such as in your home directory, so you can access it with something like "~/scripts". Also, I always rename the directory to "scripts" so I don't have to type out Script_Toybox. Do what you like.

Scripts we’ll be using:

- SCRIPTS/run_anvio_dbandstats.py : Takes all .fa files in a directory and runs everything to generate good contigs databases for you. Just runs in the local directory. If you need to use it in subdirectories, do a symbolic link (ln -s ~/scripts/run_anvio_dbandstats.py). Make sure to go in and modify the number of threads (set to 4 by default) to the number available on your system.

- SCRIPTS/get_concatenated_proteins.sh : Takes all the contigs databases you’ve generated and gets a concatenated alignment of Ribosomal LSU Proteins 1-6, both in nucleotide and amino acid format. FOR BACTERIA ONLY!!!! Modifying it to use Archaeal SCGs or Ribosomal RNAs is as easy as changing “--hmm-source” to “Rinke_et_al” or “Ribosomal_RNAs”, respectively.

- SCRIPTS/get_extended_proteins.sh : Does the same as the above script, but instead of Large Subunit proteins 1-6, it uses all the bacterial ribosomal proteins in the Campbell et al. HMM suite (49 in total).


# REMINDER

You will always forget to do this. Make sure to execute the command

```
source activate anvio4
```

before you start doing anything with Anvi'o. This activates the virtual environment for Anvi'o, hosted from within Anaconda.

---

# Script explanations

### run_anvio_dbandstats.py

This script essentially takes all the fasta files in a current directory (with the -a flag) or specific files in a comma-separated list (with the -f flag), reformats the headers to be Anvi'o-compliant, then runs the Anvi'o HMM and NCBI COG profiling scripts on it. Please note that this works for fasta files with the '.fa' or '.fasta' extension, not for '.fna'. Please change your extensions accordingly if needed.

For each input file, this script will generate two files. For "example-bug.fa", here's what will be generated:

- example-bug-FIXED.fa

- example-bug.db

What to do with these files will come up later. Please see the Anvi'o phylogenomics tutorial for an explanation of what these scripts do, and see [this link](https://github.com/jwestrob/Script_Toybox/blob/master/run_anvio_dbandstats.py) to read the script.

## get_concatenated_proteins.sh / get_extended_proteins.sh

These two scripts utilize a central file ('external-genomes.txt') with a record of all the contigs databases you want to include, then pull out the selected gene sets and generate concatenated (UNCURATED) alignments.

If you want to see all of your available genes, A. you should read the Anvi'o phylogenomics tutorial, and B. you can just do this:

```
$ anvi-get-sequences-for-hmm-hits --external-genomes external-genomes.txt \
                                   --hmm-source Campbell_et_al \
                                   --list-available-gene-names
```

You WILL have an ```external-genomes.txt``` soon. Don't worry about that part.

---

# The actual workflow

### Inputs

- FASTA files of your bins/unknown genomes

### Outputs

- Mostly up to you
- Anvi’o contigs DB for selected genomes
- Lots and lots of trees

Setup Procedure
1. Make a folder somewhere to place your genomes in. Keep in mind this is NOT the database. If you're on Microbiome01, that's /mnt/data/Phylogenomics. (If you're not with Pitt and you want to use my database, just let me know and I can get it to you.) Place all your FASTA files in this folder. First, create subdirectories for each FASTA (name them according to the file being analyzed). Then, perform the following:

```
$ ln -s SCRIPTS/run_anvio_dbandstats.py
$ source activate anvio4
$ python run_anvio_dbandstats.py -a
```

2.  Run_anvio_dbandstats.py creates a “fixed” FASTA with simplified header names that are compliant with Anvi’o’s format. I suggest removing the non “fixed” fasta files to avoid confusion. Now, move everything to its proper folder.

3. Now, I’ll describe the components of the workflow and the overall procedure. Hopefully, you have access to my database, which will be stored in a particular directory on the cluster. However, if you’re going to be adding to it (as I’m assuming is the case if you’re reading this tutorial), I’m assuming you’re able to copy it onto your local machine. Please do so. (Dealing with NCBI stuff is otherwise a bit of a pain. You don't want to have to SFTP every time you download a batch of genomes.)

I’m going to refer to the directory containing the database from here on out as GENOMES. Remember, on Microbiome01 that's /mnt/data/Phylogenomics.

The most important file you’re working with is called ‘external-genomes.txt’. Please don’t delete it. It has the list of Anvi’o contigs databases being used to pull out the concatenated alignments. You can modify this in any way you please- if you download and profile genomes from NCBI, for instance, you ought to add the names of the genomes and of the contigs databases to this document.


---
## Main Procedure

Navigate to the folder containing one of your FASTA sequences. You should have your genome (fixed by run_anvio_dbandstats.py) and a contigs db in this directory. Please run the following command (I used Grouse_Metabat_001 as an example here):
```
  $ anvi-get-sequences-for-hmm-hits -c Grouse_Metabat_001.db \
      --hmm-sources Campbell_et_al --gene_names \
      Ribosomal_L1,Ribosomal_L2,Ribosomal_L3,Ribosomal_L4,Ribosomal_L5,Ribosomal_L6 \
      --return-best-hit -o MB_001_Campbellseqs.fa
```
Now, you can use any set of genes you want. If you have an Archaeal genome, for example, instead of “--hmm-sources Campbell_et_al”, use “Rinke_et_al”. If you’d like to see a list of available sources, use the “-l” flag. If you’d like to see a list of available gene names, use the “-L” flag.

If you’d like to see a complete list of flags and options, run “anvi-get-sequences-for-hmm-hits -c [CONTIGS_DB] -h”. You must include a contigs DB or Anvi’o will get mad at you. I don’t know why this is. Please take it up with Meren.

Your next order of business is to take that to [BLAST](https://blast.ncbi.nlm.nih.gov/Blast.cgi) and search for homology. Who knows, you might even find homology strong enough that you don’t have to do the rest of this procedure!

When you’ve got that done, choose genomes from the BLAST search and download them from the [NCBI database](https://www.ncbi.nlm.nih.gov/genome/browse/#!/overview/). I recommend downloading a bunch before going to the next step. Place them in GENOMES/. As you download them from NCBI, make sure to name them with the following convention:

"[Genus name]\_[species name].fa"

Next, navigate to GENOMES/. Perform the following commands:

```
#Create a local link to my anvi'o script-of-scripts


$ ln -s SCRIPTS/run_anvio_dbandstats.py

#Profile all your genomes; create contigs DBs

$ python run_anvio_dbandstats.py -a

#Put all your fixed fasta files (anvi'o compatible headers) in Genomes/

$ mv *-fixed.fa Genomes/

#Get rid of files with old headers

$ rm *.fa
```

Now, you need to add these contigs DBs to external-genomes.txt. The way I do this is as follows:
```
$ ls -1a *.db
```
Copy the resulting names (one on each line).
Open external-genomes.txt in the text editor of your choice.
Paste them in so that they are in the following format:

Ex.  with Grouse_Metabat_001.db:

*external-genomes.txt*
```
name	contigs_db_path
Grouse_Metabat_001	 Grouse_Metabat_001.db
```

Make sure this is tab-delimited!

Now that you've added everything to your external-genomes.txt file, move all your contigs DBs to the 'contigs_dbs' folder:

```
$ mv *.db contigs_dbs/
```

Cool. Good job. Proud of you. We’re almost to the point where you can go grab a beer. Hold tight.

Now, navigate back to the directory containing your genome to be analyzed. Make a subdirectory and put your fasta file and original contigs db there. Then, copy your GENOMES/external-genomes.txt here. Our example directory, Grouse_Metabat_001, looks like this:

![directory_topography](images/dir_flowchart.png)

You’re doing wonderful. We’re very close. Next, you’re going to want to get your scripts ready. Perform the following commands:

```
$ ln -s SCRIPTS/get_concatenated_proteins.sh
$ ln -s SCRIPTS/get_extended_proteins.sh
```
Now, link all your contigs dbs here. (This looks messy, but it’s not much of an inconvenience, I promise.)

```
$ ln -s GENOMES/contigs_dbs/*.db .
```

Now, try running get_concatenated_proteins.sh. This will result in the creation of two files: concatenated-nuc-proteins.fa (Nucleotide sequences of LSU genes L1-L6) and concatenated-proteins.fa (Amino acid sequences of the same). Depending on how many genomes you had in external-genomes.txt, this might take a while. If you’re running get_extended_proteins.sh, be prepared to wait.

If something is wrong here, check your external-genomes.txt. If you forgot to remove a “db” from one of the fields on the left, or if you have a duplicate name somewhere (which can happen with all the copy-pasting you’ll be doing). If your files were generated, great! Let’s move on.

Make a directory to run your phylogenetic analysis in. I usually call them First_Tree, Second_Tree, etc. or some variant thereof. Perform the following command:

```
$ mv concatenated* First_Tree/
$ cd First_Tree/
```  

Almost there. Now, I generally like to do my trees using the nucleotide sequences (I just figure it has better phylogenetic signal; I may well be wrong). Here’s how to do that:

```
$ iqtree-omp -s concatenated-nuc-proteins.fa -bb 1000 -nt AUTO -m TEST
```

This will automatically decide how many threads to use, do ultrafast bootstrap with 1000 bootstrap trees, and test for the best model to use by Aikake and Bayesian information criteria. Now go get that beer and come back.

Great! Now, to visualize this tree, go to [iTOL](http://itol.embl.de). Create an account (you’ll be glad you did) and go to “My Trees” on the top navigation bar. Select “upload tree file” and go to the directory where you just ran iq-tree. Upload the treefile- in our case, “concatenated-nuc-proteins.fa.treefile”.

Now, if you see that your genome has a closely related friend in the phylogeny, congratulations! You’re done! Otherwise, look at the most closely related sequences and try to see if you can find any clues as to what your mystery genome might be. Then, go download more genomes from the taxon/taxa of your choice from NCBI, and repeat this whole process again! (I’ve done up to 10 trees in a single directory trying to find out what some stupid bacterium is. I don’t think it has any relatives in the database, unfortunately.)


You now know how to do the whole thing! Congrats!
