---
layout: post
title:  "How to build an Anvi'o Phylogenomics Database!"
date:   2018-06-18
excerpt: "Do what pplacer does but slower and dumber. But.... accurately."
---


### v 0.2.0

Hello there! This is the second iteration of a tutorial on how to use my phylogenomics workflow (powered by Anvi'o and ITOL).



First, let's address a key question: why would you want to do this?

I developed this workflow to get some taxonomic placement for metagenomic bins that were assembled from the digestive tract of the Greater Sage Grouse. Since this system is very poorly studied from a genomic perspective, there were very few entries in the NCBI database that aligned with high identity to any marker genes from these bins. (That, and I hadn't read Tyler Barnum's <a href="https://tylerbarnum.wordpress.com/2018/06/22/searching-uncultivated-bacteria-and-archaea-uba-genomes-for-important-genes/"><font color="blue">very helpful blog post</font></a> on how to query the IMG database.)

If you find yourself with a bunch of bins and no way to get a good taxonomic placement for them, this workflow will help you out! If you happen upon this and know of a way to do any of this better, please let me know.

This is in very large part based on the [Anvi'o Phylogenomics Workflow](http://merenlab.org/2017/06/07/phylogenomics/) from the Meren Lab. If you're interested in this stuff, definitely read this tutorial; there's lots of functionalities available in Anvi'o that I didn't use here (such as visualizing the tree in a python environment with ete3, and how to create custom HMM suites to use with these scripts instead of the provided SCG sets).

This is kind of a stripped-down version of what that page describes, with examples of how to go about adding to the database along with some scripts-of-scripts I've made to help things go faster.



_**Index**_

  1. [Installation](#Installation)
    - [Installing Conda](#installing-conda)
    - [Installing Anvi'o](#installing-anvio)
    - [Installing iQ-TREE](#installing-iqtree)
  2. [Basic Overview and Outline](#overview)
  3. [Scripts](#scripts)

Please note that the following tutorial only applies to Unix-based systems. If you don't have a Unix-based system, consider getting one. You'll be glad you did (and Ubuntu is free)!

---
<a name="Installation"></a>
## Installation

Here's a list of dependencies for this workflow:

  - Python
  - Anaconda
  - Anvi'o
  - iQ-TREE (or whatever phylogenetic tree building software you prefer; Anvi'o has its own)
  - Command line proficiency (human only)

If you don't have Python installed, go ahead and install that (instructions are distribution-specific, and I leave it in your capable hands).

<a name="installing-conda"></a>
## Installling Anaconda

First, go [here](https://www.anaconda.com/download/#linux) to download the Anaconda installer. Please ensure you download the version that fits the Python version you have.

Second, go to wherever you downloaded the file and perform the following:

```
  $ bash Anaconda[VERSION NAME].sh
```

Then follow the helpful instructions. The wonderful thing about Anaconda is that this will work fine even if you're on a cluster where you don't have sudo access. Trying to install software without sudo can be aggravating, and conda tends to get past that particular hurdle very well.

This will create a local installation; if you're on a cluster with multiple users, this will not give them access to it!! In order to do so you will likely have to do a couple things, like:

 - modify the conda directory (which you will specify upon install) to be accessible to all users if necessary.
 - Take the line generated by conda in your .bashrc (in your home directory; try using 'ls -a' to find it) and have other users put it in their .bashrc files.

Congratulations! From this point on installing things should be easy. Make sure you can run conda:

```
  $ conda --version
```

If everything's good, proceed. Otherwise... try again or contact me with your error. Google is also a reliable friend in instances like these, and you will likely be able to solve this most quickly by googling it. Please try that before contacting me or I will tell you to google it.

<a name="installing-anvio"></a>
### Installing Anvi'o
---
Watch this.

```
conda create -n anvio4 -c bioconda -c conda-forge python=3 anvio=4
```

Boom.

See the Meren Lab's (far superior and more thorough) instructions for alternative installation methods [here](http://merenlab.org/2016/06/26/installation-v2/).

<a name="installing-iqtree"></a>
### Installing iqtree
---
And again, bask in the glory of easy software installation.

```
  $ conda install -c bioconda iqtree
```

Ta-dah!


---

<a name="overview"></a>
## Basic overview and outline

The phylogenomics workflow I've settled on here (using some beautiful, well-documented software) is fairly straightforward, though it does involve a couple of steps.
The main purpose behind it was to create a database to use to generate taxonomic placements for unknown MAGs from a sample of Sage Grouse secum. We got several MAGs out of my assembly pipeline (<a href="https://github.com/jwestrob/Metaxas"><font color="blue">Metaxas</font></a>; if you're trying to use this please let me know so I can help) but had no way of doing taxonomic ID for any of them, save for one _Megamonas_ MAG.

Essentially, Anvi'o has several suites of HMMs for bacterial and archaeal single-copy genes, as well as ribosomal RNA genes. Again, the basic gist of what I do here is covered in far greater detail here: [http://merenlab.org/2017/06/07/phylogenomics/](http://merenlab.org/2017/06/07/phylogenomics/) I highly recommend you look there for a good understanding of all the things Anvi'o can do, as well as bash tips and tricks.


---

Please note that I have made several scripts to make this process a lot easier.

The scripts are hosted at https://github.com/jwestrob/Script_Toybox. If you are going to proceed with the tutorial, please clone this repository onto your computer as so:

```
git clone https://github.com/jwestrob/Script_Toybox.git
```

From here on out, I will refer to the directory where you placed this repository as "SCRIPTS". I recommend putting it someplace convenient, such as in your home directory, so you can access it with something like "~/scripts". Also, I always rename the directory to "scripts" so I don't have to type out Script_Toybox. Do what you like.

Scripts we’ll be using:

- SCRIPTS/run_anvio_dbandstats.py : Takes all .fa files in a directory and runs everything to generate good contigs databases for you. Just runs in the local directory. If you need to use it in subdirectories, do a symbolic link (ln -s ~/scripts/run_anvio_dbandstats.py). Make sure to go in and modify the number of threads (set to 4 by default) to the number available on your system.

- SCRIPTS/get_concatenated_proteins.sh : Takes all the contigs databases you’ve generated and gets a concatenated alignment of Ribosomal LSU Proteins 1-6, both in nucleotide and amino acid format. FOR BACTERIA ONLY!!!! Modifying it to use Archaeal SCGs or Ribosomal RNAs is as easy as changing “--hmm-source” to “Rinke_et_al” or “Ribosomal_RNAs”, respectively.

- SCRIPTS/get_extended_proteins.sh : Does the same as the above script, but instead of Large Subunit proteins 1-6, it uses all the bacterial ribosomal proteins in the Campbell et al. HMM suite (49 in total).


# REMINDER

You will always forget to do this. Make sure to execute the command

```
source activate anvio4
```

before you start doing anything with Anvi'o. This activates the virtual environment for Anvi'o, hosted from within Anaconda.

---

<a name="scripts"></a>

## Script explanations

### run_anvio_dbandstats.py
```
$ python ~/scripts/run_anvio_dbandstats.py -h

usage: run_anvio_dbandstats.py [-h] [-a] [-f [fastas to process]]
                               [-t threads to use]

Run anvi'o stuff on either all files in a directory (-a) or sets of files
(-s). Remember to activate Anvi'o first!

optional arguments:
  -h, --help            show this help message and exit
  -a                    Run db and stats on all .fa/.fasta files in directory.
  -f [fastas to process]
                        COMMA-SEPARATED list of fastas to operate on.
  -t threads to use     How many threads do you want Anvi'o to use?
```

This script essentially takes all the fasta files in a current directory (with the -a flag) or specific files in a comma-separated list (with the -f flag), reformats the headers to be Anvi'o-compliant, then runs the Anvi'o HMM and NCBI COG profiling scripts on it. Please note that this works for fasta files with the '.fa' or '.fasta' extension, not for '.fna'. Please change your extensions accordingly if needed.

For each input file, this script will generate two files. For "example-bug.fa", here's what will be generated:

- example-bug-FIXED.fa

- example-bug.db

What to do with these files will come up later. Please see the Anvi'o phylogenomics tutorial for an explanation of what these scripts do, and see [this link](https://github.com/jwestrob/Script_Toybox/blob/master/run_anvio_dbandstats.py) to read the script.

## get_concatenated_proteins.sh / get_extended_proteins.sh

These two scripts utilize a central file ('external-genomes.txt') with a record of all the contigs databases you want to include, then pull out the selected gene sets and generate concatenated (UNCURATED) alignments.

If you want to see all of your available genes, A. you should read the Anvi'o phylogenomics tutorial, and B. you can just do this:

```
$ anvi-get-sequences-for-hmm-hits --external-genomes external-genomes.txt \
                                   --hmm-source Campbell_et_al \
                                   --list-available-gene-names
```

You WILL have an ```external-genomes.txt``` soon. Don't worry about that part.

---

# The actual workflow

### Inputs

- FASTA files of your bins/unknown genomes

### Outputs

- Mostly up to you
- Anvi’o contigs DB for selected genomes
- Lots and lots of trees

Setup Procedure
1. Make a folder somewhere to place your bins in. Keep in mind this is NOT the database. Place all your bin FASTA files in this folder. First, create subdirectories for each FASTA (name them according to the file being analyzed). Then, perform the following:

```
$ ln -s SCRIPTS/run_anvio_dbandstats.py .
$ source activate anvio4
$ python run_anvio_dbandstats.py -a
```

This will

2.  Run_anvio_dbandstats.py creates a “fixed” FASTA with simplified header names that are compliant with Anvi’o’s format. I suggest removing the non “fixed” fasta files to avoid confusion. Now, move everything to its proper folder.

3. Now, I’ll describe the components of the workflow and the overall procedure. Hopefully, you have access to my database, which will be stored in a particular directory on the cluster. However, if you’re going to be adding to it (as I’m assuming is the case if you’re reading this tutorial), I’m assuming you’re able to copy it onto your local machine. Please do so. (Dealing with NCBI genomes is otherwise a bit of a pain. You don't want to have to SFTP every time you download a batch of genomes.)

I’m going to refer to the directory containing the database from here on out as BINS.

The most important file you’re working with is called ‘external-genomes.txt’. Please don’t delete it. It has the list of Anvi’o contigs databases being used to pull out the concatenated alignments. You can modify this in any way you please- if you download and profile genomes from NCBI, for instance, you ought to add the names of the genomes and of the contigs databases to this document.


---
## Main Procedure



Navigate to the folder containing one of your FASTA sequences. You should have your genome (fixed by run_anvio_dbandstats.py) and a contigs db in this directory. Please run the following command (I used Grouse_Metabat_001 as an example here):
```
  $ anvi-get-sequences-for-hmm-hits -c Grouse_Metabat_001.db \
      --hmm-sources Campbell_et_al --gene_names \
      Ribosomal_L1,Ribosomal_L2,Ribosomal_L3,Ribosomal_L4,Ribosomal_L5,Ribosomal_L6 \
      --return-best-hit -o MB_001_Campbellseqs.fa
```
Now, you can use any set of genes you want. If you have an Archaeal genome, for example, instead of “--hmm-sources Campbell_et_al”, use “Rinke_et_al”. If you’d like to see a list of available sources, use the “-l” flag. If you’d like to see a list of available gene names, use the “-L” flag.

If you’d like to see a complete list of flags and options, run “anvi-get-sequences-for-hmm-hits -c [CONTIGS_DB] -h”. You must include a contigs DB or Anvi’o will get mad at you. I don’t know why this is. Please take it up with Meren.

Your next order of business is to take that to [BLAST](https://blast.ncbi.nlm.nih.gov/Blast.cgi) and search for homology. Who knows, you might even find homology strong enough that you don’t have to do the rest of this procedure!

When you’ve got that done, choose genomes from the BLAST search and download them from the [NCBI database](https://www.ncbi.nlm.nih.gov/genome/browse/#!/overview/). I recommend downloading a bunch before going to the next step. Place them in GENOMES/. As you download them from NCBI, make sure to name them with the following convention:

"[Genus name]\_[species name].fa"

Next, navigate to GENOMES/. Perform the following commands:

```
#Create a local link to my anvi'o script-of-scripts


$ ln -s SCRIPTS/run_anvio_dbandstats.py

#Profile all your genomes; create contigs DBs

$ python run_anvio_dbandstats.py -a

#Put all your fixed fasta files (anvi'o compatible headers) in Genomes/

$ mv *-fixed.fa Genomes/

#Get rid of files with old headers

$ rm *.fa
```

Now, you need to add these contigs DBs to external-genomes.txt. The way I do this is as follows:
```
$ ls -1a *.db
```
Copy the resulting names (one on each line).
Open external-genomes.txt in the text editor of your choice.
Paste them in so that they are in the following format:

Ex.  with Grouse_Metabat_001.db:

*external-genomes.txt*
```
name	contigs_db_path
Grouse_Metabat_001	 Grouse_Metabat_001.db
```

Alternatively, if it makes things easier for you, you don't have to take off the '.db' for the entry in the 'name' column:

```
name	contigs_db_path
Grouse_Metabat_001.db	 Grouse_Metabat_001.db
```

Make sure this is tab-delimited! I will make a script to do this automatically very soon, I promise you.

Now that you've added everything to your external-genomes.txt file, move all your contigs DBs to the 'contigs_dbs' folder:

```
$ mv *.db contigs_dbs/
```

Cool. Good job. Proud of you. We’re almost to the point where you can go grab a beer. Hold tight.

Now, navigate back to the directory containing your genome to be analyzed. Make a subdirectory and put your fasta file and original contigs db there. Then, copy your GENOMES/external-genomes.txt here. Our example directory, Grouse_Metabat_001, looks like this:

![directory_topography](images/dir_flowchart.png)

You’re doing wonderful. We’re very close. Next, you’re going to want to get your scripts ready. Perform the following commands:

```
$ ln -s SCRIPTS/get_concatenated_proteins.sh
$ ln -s SCRIPTS/get_extended_proteins.sh
```
Now, link all your contigs dbs here. (This looks messy, but it’s not much of an inconvenience, I promise.)

```
$ ln -s GENOMES/contigs_dbs/*.db .
```

Now, try running get_concatenated_proteins.sh. This will result in the creation of two files: concatenated-nuc-proteins.fa (Nucleotide sequences of LSU genes L1-L6) and concatenated-proteins.fa (Amino acid sequences of the same). Depending on how many genomes you had in external-genomes.txt, this might take a while. If you’re running get_extended_proteins.sh, be prepared to wait.

If something is wrong here, check your external-genomes.txt. If you forgot to remove a “db” from one of the fields on the left, or if you have a duplicate name somewhere (which can happen with all the copy-pasting you’ll be doing). If your files were generated, great! Let’s move on.

Make a directory to run your phylogenetic analysis in. I usually call them First_Tree, Second_Tree, etc. or some variant thereof. Perform the following command:

```
$ mv concatenated* First_Tree/
$ cd First_Tree/
```  

Almost there. Now, I generally like to do my trees using the nucleotide sequences (I just figure it has better phylogenetic signal; I may well be wrong). Here’s how to do that:

```
$ iqtree-omp -s concatenated-nuc-proteins.fa -bb 1000 -nt AUTO -m TEST
```

This will automatically decide how many threads to use, do ultrafast bootstrap with 1000 bootstrap trees, and test for the best model to use by Aikake and Bayesian information criteria. Now go get that beer and come back.

Great! Now, to visualize this tree, go to [iTOL](http://itol.embl.de). Create an account (you’ll be glad you did) and go to “My Trees” on the top navigation bar. Select “upload tree file” and go to the directory where you just ran iq-tree. Upload the treefile- in our case, “concatenated-nuc-proteins.fa.treefile”.

Now, if you see that your genome has a closely related friend in the phylogeny, congratulations! You’re done! Otherwise, look at the most closely related sequences and try to see if you can find any clues as to what your mystery genome might be. Then, go download more genomes from the taxon/taxa of your choice from NCBI, and repeat this whole process again! (I’ve done up to 10 trees in a single directory trying to find out what some stupid bacterium is. I don’t think it has any relatives in the database, unfortunately.)


You now know how to do the whole thing! Congrats!
