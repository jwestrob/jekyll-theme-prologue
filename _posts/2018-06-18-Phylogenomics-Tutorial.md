---
layout: post
title:  "How to perform taxonomic placement with Anvi'o and the NCBI database!"
date:   2018-06-22
excerpt: "Do what pplacer does but slower... and with access to the NCBI database."
---


### v 0.2.0

Hello there! This is the second iteration of a tutorial on how to use my phylogenomics workflow (powered by Anvi'o and ITOL).

## _**Index**_

<div id="toc_container">
<p class="toc_title">Index</p>
<ul class="toc_list">
  <li><a href="#First_Point_Header">1. Installation</a><br/>
  <ul>
    <li><a href="#installing-conda">1.1 Installing Conda</a></li>
    <li><a href="#installing-anvio">1.2 Installing Anvi'o</a></li>
    <li><a href="#installing-iqtree">1.3 Installing iQ-TREE</a></li>
  </ul>
</li>
<li><a href="#overview">2. Basic Overview and Outline</a></li><br/>
<li><a href="#scripts">3. Scripts</a></li><br/>
  <li><a href="#workflow">4. The Actual Workflow</a></li><br/>
  <ul>
    <li><a href="#setting-up">4.1 Setting Up</a></li>
    <li><a href="#get-ribosomal-hits">4.2 Getting Ribosomal Gene HMM Hits From Your Bin</a></li>
    <li><a href="#downloading-genomes">4.3 Downloading Genomes</a></li>
    <li><a href="#adding-to-db">4.4 Profiling and Adding Genomes to Your New Database</a></li>
    <li><a href="#extracting-tree">4.5 Extracting Gene Hits and Making a Tree</a></li>
  </ul>
<li><a href="#references">5. References</a></li>
</ul>
</div>



First, let's address a key question: why would you want to do this?

I developed this workflow to get some taxonomic placement for metagenomic bins that were assembled from the digestive tract of the Greater Sage Grouse. Since this system is very poorly studied from a genomic perspective, there were very few entries in the NCBI database that aligned with high identity to any marker genes from these bins. (That, and I hadn't read Tyler Barnum's <a href="https://tylerbarnum.wordpress.com/2018/06/22/searching-uncultivated-bacteria-and-archaea-uba-genomes-for-important-genes/"><font color="blue">very helpful blog post</font></a> on how to query the IMG database.)

If you find yourself with a bunch of bins and no way to get a good taxonomic placement for them, this workflow will help you out! If you happen upon this and know of a way to do any of this better, please let me know.

This is in very large part based on the [Anvi'o Phylogenomics Workflow](http://merenlab.org/2017/06/07/phylogenomics/) from the Meren Lab. If you're interested in this stuff, definitely read this tutorial; there's lots of functionalities available in Anvi'o that I didn't use here (such as visualizing the tree in a python environment with fasttree, and how to create custom HMM suites to use with these scripts instead of the provided SCG sets).

This is kind of a stripped-down version of what that page describes. I found that there are some good resources on NCBI to help identify  unknown bins, and so I wanted to provide a specific example of how to go about constructing and adding to a database of your own using the procedure I kind of cobbled together from various online resources. The Anvi'o phylogenomics tutorial is awesome, but I wanted to include a specific example (by request) and show how to fetch things off the NCBI database in order to get a good idea of what a bin might actually be.





Please note that the following tutorial only applies to Unix-based systems. If you don't have a Unix-based system, consider getting one. You'll be glad you did (and Ubuntu is free)!

---
<a name="Installation"></a>
## Installation

Here's a list of dependencies for this workflow:

  - Python
  - Anaconda
  - Anvi'o
  - iQ-TREE (or whatever phylogenetic tree building software you prefer; Anvi'o has its own)
  - Command line proficiency
  - An internet connection
  - Time

If you don't have Python installed, go ahead and install that (instructions are distribution-specific, and I leave it in your capable hands).

<a name="installing-conda"></a>
## Installling Anaconda

First, go [here](https://www.anaconda.com/download/#linux) to download the Anaconda installer. Please ensure you download the version that fits the Python version you have.

Second, go to wherever you downloaded the file and perform the following:

```
  $ bash Anaconda[VERSION NAME].sh
```

Then follow the helpful instructions. The wonderful thing about Anaconda is that this will work fine even if you're on a cluster where you don't have sudo access. Trying to install software without sudo can be aggravating, and conda tends to get past that particular hurdle very well.

This will create a local installation; if you're on a cluster with multiple users, this will not give them access to it!! In order to do so you will likely have to do a couple things, like:

 - modify the conda directory (which you will specify upon install) to be accessible to all users if necessary.
 - Take the line generated by conda in your .bashrc (in your home directory; try using 'ls -a' to find it) and have other users put it in their .bashrc files.

Congratulations! From this point on installing things should be easy. Make sure you can run conda:

```
  $ conda --version
```

If everything's good, proceed. Otherwise... try again or contact me with your error. Google is also a reliable friend in instances like these, and you will likely be able to solve this most quickly by googling it. Please try that before contacting me or I will tell you to google it.

<a name="installing-anvio"></a>
### Installing Anvi'o
---
Watch this.

```
conda create -n anvio4 -c bioconda -c conda-forge python=3 anvio=4
```

Boom.

See the Meren Lab's (far superior and more thorough) instructions for alternative installation methods [here](http://merenlab.org/2016/06/26/installation-v2/).

<a name="installing-iqtree"></a>
### Installing iqtree
---
And again, bask in the glory of easy software installation.

```
  $ conda install -c bioconda iqtree
```

Ta-dah!


---

<a name="overview"></a>
## Basic overview and outline

The phylogenomics workflow I've settled on here (using some beautiful, well-documented software) is fairly straightforward, though it does involve a couple of steps.
The main purpose behind it was to create a database to use to generate taxonomic placements for unknown MAGs from a sample of Sage Grouse secum. We got several MAGs out of my assembly pipeline (<a href="https://github.com/jwestrob/Metaxas"><font color="blue">Metaxas</font></a>; if you're trying to use this please let me know so I can help) but had no way of doing taxonomic ID for any of them, save for one _Megamonas_ MAG.

Essentially, Anvi'o has several suites of HMMs for bacterial and archaeal single-copy genes, as well as ribosomal RNA genes. Again, the basic gist of what I do here is covered in far greater detail here: [http://merenlab.org/2017/06/07/phylogenomics/](http://merenlab.org/2017/06/07/phylogenomics/) I highly recommend you look there for a good understanding of all the things Anvi'o can do, as well as bash tips and tricks.


---

Please note that I have made several scripts to make this process a lot easier.

The scripts are hosted at https://github.com/jwestrob/Script_Toybox. If you are going to proceed with the tutorial, please clone this repository onto your computer as so:

```
git clone https://github.com/jwestrob/Script_Toybox.git
```

From here on out, I will refer to the directory where you placed this repository as "SCRIPTS". I recommend putting it someplace convenient, such as in your home directory, so you can access it with something like "~/scripts". Also, I always rename the directory to "scripts" so I don't have to type out Script_Toybox. Do what you like.

<a name="link"></a>
The best method, though, is to use the following trick:

  - cd into that directory and do ```pwd```. Copy the directory information.

  - Now, open your .bashrc (sudo nano ~/.bashrc on your local machine; no sudo if you're on a cluster) and enter the following line:
    ```
    export SCRIPTS="/path/to/cloned/repository"
    ```

  - Now, re-load your .bashrc with the following command:
    ```
    $ source ~/.bashrc
    ```
    and you can now access the directory via $SCRIPTS. (e.g. ```$ ls $SCRIPTS```.)

Scripts we’ll be using:

- $SCRIPTS/run_anvio_dbandstats.py : Takes all .fa files in a directory and runs everything to generate good contigs databases for you. Just runs in the local directory. If you need to use it in subdirectories, do a symbolic link (ln -s ~/scripts/run_anvio_dbandstats.py). Make sure to go in and modify the number of threads (set to 4 by default) to the number available on your system.

- $SCRIPTS/get_concatenated_proteins.sh : Takes all the contigs databases you’ve generated and gets a concatenated alignment of Ribosomal LSU Proteins 1-6, both in nucleotide and amino acid format. FOR BACTERIA ONLY!!!! Modifying it to use Archaeal SCGs or Ribosomal RNAs is as easy as changing “--hmm-source” to “Rinke_et_al” or “Ribosomal_RNAs”, respectively.

- $SCRIPTS/get_extended_proteins.sh : Does the same as the above script, but instead of Large Subunit proteins 1-6, it uses all the bacterial ribosomal proteins in the Campbell et al. HMM suite (49 in total).


# REMINDER

You will always forget to do this. Make sure to execute the command

```
source activate anvio4
```

before you start doing anything with Anvi'o. This activates the virtual environment for Anvi'o, hosted from within Anaconda.

---

<a name="scripts"></a>

## Script explanations

### run_anvio_dbandstats.py
```
$ python ~/scripts/run_anvio_dbandstats.py -h

usage: run_anvio_dbandstats.py [-h] [-a] [-f [fastas to process]]
                               [-t threads to use]

Run anvi'o stuff on either all files in a directory (-a) or sets of files
(-s). Remember to activate Anvi'o first!

optional arguments:
  -h, --help            show this help message and exit
  -a                    Run db and stats on all .fa/.fasta files in directory.
  -f [fastas to process]
                        COMMA-SEPARATED list of fastas to operate on.
  -t threads to use     How many threads do you want Anvi'o to use?
```

This script essentially takes all the fasta files in a current directory (with the -a flag) or specific files in a comma-separated list (with the -f flag), reformats the headers to be Anvi'o-compliant, then runs the Anvi'o HMM and NCBI COG profiling scripts on it. Please note that this works for fasta files with the '.fa' or '.fasta' extension, not for '.fna'. Please change your extensions accordingly if needed.

For each input file, this script will generate two files. For "example-bug.fa", here's what will be generated:

- example-bug-FIXED.fa

- example-bug.db

What to do with these files will come up later. Please see the Anvi'o phylogenomics tutorial for an explanation of what these scripts do, and see [this link](https://github.com/jwestrob/Script_Toybox/blob/master/run_anvio_dbandstats.py) to read the script.

## get_concatenated_proteins.sh / get_extended_proteins.sh

These two scripts utilize a central file ('external-genomes.txt') with a record of all the contigs databases you want to include, then pull out the selected gene sets and generate concatenated (UNCURATED) alignments.

If you want to see all of your available genes, A. you should read the Anvi'o phylogenomics tutorial, and B. you can just do this:

```
$ anvi-get-sequences-for-hmm-hits --external-genomes external-genomes.txt \
                                   --hmm-source Campbell_et_al \
                                   --list-available-gene-names
```

You WILL have an ```external-genomes.txt``` soon. Don't worry about that part.

---

<a name="Workflow"></a>
## The actual workflow

### Inputs

- FASTA files of your bins/unknown genomes
- The SCRIPTS directory described above (you can totally get by without this though)


### Outputs

- Mostly up to you
- Anvi’o contigs DB for selected genomes
- Lots and lots of trees

<a name="setting-up"></a>
### Setting up!
First make a directory to work in (I named mine Phylogenomics_Tutorial):

```
$ mkdir Phylogenomics_Tutorial
$ cd Phylogenomics_Tutorial
$ mkdir Bins
$ mkdir Genomes
$ cd Bins
```
You should have a directory with the following structure:

```
Phylogenomics_Tutorial/
├── Bins
└── Genomes

2 directories, 0 files
```

I have an example set up, too! If you'd like to follow along, download the bin that I've hosted as so:

```
$ wget jwestrob.github.io/assets/genome_files/Grouse_MyCC56_008.fa
```

Spoiler: I've identified this as belonging to genome _Megamonas_, with its closest related genome being a member of the species _M. hypermegale_, which was previously characterized in the secums (seca?) of ducks and chickens. Just roll with it for now.

Setup Procedure
- You should now be in the Bins/ folder. If you're following the example, you're just going to have one fasta here: ```Grouse_MyCC56_008.fa```. Otherwise, put your unknown bins here. First, go ahead and profile your bins with Anvi'o (make sure to provide a value for NUM_THREADS, either manually or by setting ```NUM_THREADS = 4``` or somesuch):

For now, all you have in the Bins/ directory is ```Grouse_MyCC56_008.fa```. First, make a directory for this bin (I use ```mkdir Grouse_MyCC_008```). Now, run this code to profile your bin as an Anvi'o contigs DB:

```
$ source activate anvio4
$ python $SCRIPTS/run_anvio_dbandstats.py -a -t $NUM_THREADS
```

For each bin fasta, this will generate two files. Let's use our example to see- this is just after running the above command:
```
$ tree Bins/
Bins
├── Grouse_MyCC56_008.db
├── Grouse_MyCC56_008.fa
├── Grouse_MyCC56_008-fixed.fa
└── MyCC_008
```

Where we started with just ```Grouse_MyCC56_008.fa```, now we have ```Grouse_MyCC56_008.db``` and ```Grouse_myCC56_008-fixed.fa```. The latter file is a “fixed” FASTA with simplified header names that are compliant with Anvi’o’s format; the ```.db``` file is the Anvi'o contigs DB, with HMM hits for three different sets of HMMs: Ribosomal RNAs, Bacterial SCGs (Campbell et al.), and Archaeal SCGs (Rinke et al.).


- I suggest removing the non-“fixed” fasta files to avoid confusion. Now, move everything to its proper folder; in this case, just do this:

  ```
  $ mv Grouse_MyCC_008* MyCC_008
  ```

Great! Now let's make a folder in which we'll store genomes we'll be pulling from the NCBI database (or wherever else you might like). Execute the following commands:

```
$ cd ../Genomes

#Create a file external-genomes.txt
$ touch external-genomes.txt

#Add header to external-genomes.txt
$ echo name$'\t'contigs_db_path >> external-genomes.txt

#Make directory to store FASTA files in
$ mkdir Genomes

#Make directory to store Anvi'o contigs DBs in
$ mkdir contigs_dbs
```

Your ```Genomes/``` directory should now look like this:

```
$ tree Genomes/

Genomes
├── contigs_dbs
├── external-genomes.txt
└── Genomes

2 directories, 1 file
```

(I’m going to refer to the directory containing the example/bins from here on out as $BINS and the directory containing the external genomes as $GENOMES. If you want to make an environment variable to access these directories, <a href="#link"><font color="blue">here's how to do that.</font></a>)

---
<a name="get-ribosomal-hits"></a>
## Get Ribosomal Hits From Your Bin

Navigate to the folder containing one of your FASTA bins. You should have your genome (fixed by run_anvio_dbandstats.py) and a contigs db in this directory. For our example, that directory is BINS/.

Now, the first thing I do is pull out the sequences for the large ribosomal subunit. Of course, Ribosomal small subunit protein S3 is also a very popular protein to use for phylogenetic analysis; modify this as you like.

I would also like to point out that the [Anvi'o phylogenomics tutorial](http://merenlab.org/2017/06/07/phylogenomics/#working-with-fasta-files) is really really good reading material for this bit, if you haven't read it already.

For our example, the command is as follows:

```
  $ anvi-get-sequences-for-hmm-hits -c Grouse_MyCC56_008.db \
  --hmm-sources Campbell_et_al \
  --gene-names Ribosomal_L1,Ribosomal_L2,Ribosomal_L3,Ribosomal_L4,Ribosomal_L5,Ribosomal_L6 \
  --return-best-hit -o MC_008_Campbellseqs.fa
```

I also like to get the ribosomal RNA genes. Here's the command to do that, but PLEASE BE ADVISED that there are no ribosomal RNA hits for this particular bin. This is just an example.

```
  $ anvi-get-sequences-for-hmm-hits -c Grouse_MyCC56_008.db --hmm-sources Ribosomal_RNAs \
  --gene-names Bacterial_16S_rRNA,Bacterial_23S_rRNA,Bacterial_5S_rRNA \
  --return-best-hit -o MC_008_rRNAs.fa
```

Now, you can use any set of genes you want.
- If you have an Archaeal genome, for example, instead of “--hmm-sources Campbell_et_al”, use “Rinke_et_al”.
- If you want to see ribosomal RNA hits, use "--hmm-sources Ribosomal_RNAs"
- If you’d like to see a list of available sources, use the “-l” flag. If you’d like to see a list of available gene names for a particular source, use the “-L” flag.

If you’d like to see a complete list of flags and options, run “anvi-get-sequences-for-hmm-hits -c [CONTIGS_DB] -h”. You must include a contigs DB or Anvi’o will get mad at you.

#### Side Note:

- Anvi'o gets a little nervous when you include the '--return-best-hit' flag.  That's OK. It's just in case there are multiple hits within the bin; unlikely but still a possibility we'd like to work around.

To be thorough, I recommend extracting the Campbell or Rinke et al. sequences (not both) along with the ribosomal RNAs, concatenating them, and then BLASTing the resulting fasta file. The problem with relying on just the ribosomal RNAs is that sometimes you just don't have any; it's always nice to get a good 16S hit though.

Your next order of business is to take the resulting FASTA to [BLAST](https://blast.ncbi.nlm.nih.gov/Blast.cgi) and search for homology. Who knows, you might even find homology strong enough that you don’t have to do the rest of this procedure!

- For our example, upload ```Phylogenomics_Tutorial/Bins/MyCC_008/MC_008_Campbellseqs.fa``` to BLAST. You'll notice several of these proteins have high-identity (100% coverage, >95% nucleotide identity) alignments to _Megamonas hypermegale_ genomes. There is a reason for that.

<a name="downloading-genomes"></a>
### Downloading Genomes

When you’ve got that done, our next step is to select genomes that have high homology from your BLAST search and grab them from the <a href="https://www.ncbi.nlm.nih.gov/genome/browse/#!/overview/"><font color="blue">NCBI Genome Database</font></a>. I recommend downloading a bunch before going to the next step. Place them in Phylogenomics_Tutorial/Genomes/ (aka $GENOMES).

For our example, we know that we have something in genus _Megamonas_. _Megamonas_ is in the order _Selenomonadales_, so go ahead and search "Selenomonadales" in the top bar. You'll notice that there are several _Megamonas_ genomes, as well as several from other genera within _Selenomonadales_. Download whichever ones you like! As for my analysis, I chose:

  - _Megamonas_ sp.
  - _Megamonas hypermegale_
  - _Megamonas funiformis_
  - _Megamonas rupellensis_
  - _Anaerovibro lipolyticus_
  - _Centipedia periodontii_
  - _Dendrosporobacter quercicolus_
  - _Mitsuokella jalaudinii_
  - _Propionispira raffinosivorans_
  - _Selenomonas ruminantium_
  - _Sporomusa acidovorans_

Please note that I chose the genomes outside genus _Megamonas_ relatively naively, mostly based on how cool the name was.

As you download these genome fasta files from NCBI, I suggest you name them using the following convention:

"[Genus name]\_[species name].fa"

Now, for many of these genomes, getting the actual FASTA file is a straightforward process. If you click on the entry in the NCBI Genome Database search, you'll either see a box at the top of the page that looks like this:

![Easy Download](/assets/images/Megamonas_funiformis.png)

In which case just select 'Download sequences in FASTA format for genome'- you'll receive a download in .fna.gz format. Gunzip it (```gunzip whatever.fna.gz```) and rename it (```mv whatever.fna Genus_species.fa```).

Or you'll see a page that looks like this:

![Hard Download](/assets/images/Megamonas.png)

In which case you should click the link that says 'Assembly' on the top right. On the following page, you'll likely see a couple of alternative assemblies; I like to select the assembly based on Contig N50, though I know that's not always an entirely robust metric by which to choose your assemblies. It suits our purposes here, though, I think. Click "Sort by significance" on the top of the page and select "Contig N50 (down)". Select your preferred assembly (with the box next to the assembly name), click 'Download Assemblies', select 'GenBank' as your source database, and 'Genomic FASTA' as your file type.

You'll get a .tar file. I recommend renaming it when you download it; it helps avoid confusion.
Untar it with ```tar xvf [TAR FILE].tar```. This will make a directory called "ncbi-genomes-20XX-XX-XX", where the latter part will be the date you downloaded the file.

Then, gunzip everything in the directory: ```gunzip ncbi-genomes-20XX-XX-XX/*.gz```.

Find the largest assembly (using ```ls -thora ncbi-genomes-20XX-XX-XX/```), and copy that into your working directory under the name you want!

(```cp GCA_[lots of numbers and letters].fna ./Megamonas_sp.fa```)

You can now keep the ncbi-genomes folder (which likely contains multiple assemblies), in which case rename it, or you can delete it. I usually get rid of it.


### An Aside
---

Lots of these genomes were assembled by researchers at the University of Queensland (Parks et al.) for publication in the really cool 2017 paper <a href="https://www.nature.com/articles/s41564-017-0012-7"><font color="blue">Recovery of nearly 8,000 metagenome-assembled genomes substantially expands the tree of life</font></a>. You'll notice that genomes assembled for this paper will pop up a lot when you traverse through the NCBI database. Shouts out to Parks et al. for this- it's a huge boon to have all these sequences available.

---
<a name="adding-to-db"></a>
### Profiling and adding genomes to the database

Next, go ahead and profile all the genomes you downloaded using Anvi'o:

```
#Create a symbolic link to my anvi'o script-of-scripts

$ ln -s $SCRIPTS/run_anvio_dbandstats.py .

#Profile all your genomes; create contigs DBs

$ python run_anvio_dbandstats.py -a -t $NUM_THREADS

#Put all your fixed fasta files (anvi'o compatible headers) in Genomes/

$ mv *-fixed.fa Genomes/

#Get rid of files with old headers (optional):

$ rm *.fa
```

Now, you need to add these contigs DBs to external-genomes.txt. The way I do this is as follows:
```
$ ls -1a *.db
```
Copy the resulting names (one on each line).
Open external-genomes.txt in the text editor of your choice.
Paste them in so that they are in the following format:

Ex.  with Grouse_Metabat_001.db:

*external-genomes.txt*
```
name	contigs_db_path
Grouse_Metabat_001	 Grouse_Metabat_001.db
```

Alternatively, if it makes things easier for you, you don't have to take off the '.db' for the entry in the 'name' column:

```
name	contigs_db_path
Grouse_Metabat_001.db	 Grouse_Metabat_001.db
```

Make sure this is tab-delimited!

**(I will make a script to do this automatically very soon, I promise.)**

Now that you've added everything to your external-genomes.txt file, move all your contigs DBs to the 'contigs_dbs' folder:

```
$ mv *.db contigs_dbs/
```

Cool. Good job; we’re almost done. Hold tight.

Now, navigate back to the $BINS folder. Enter the directory for the bin you want to analyze. Make a subdirectory (for our example, name it MyCC_008) and put your bin FASTA file and original contigs db there. Then, copy your GENOMES/external-genomes.txt here. Our example directory, MyCC_008, now looks like this:

```
$ tree MyCC_008/

MyCC_008/
└── MyCC_008
    ├── Grouse_MyCC56_008.db
    ├── Grouse_MyCC56_008.fa
    ├── Grouse_MyCC56_008-fixed.fa
    └── MC_008_Campbellseqs.fa

1 directory, 4 files
```

Trust me, it will be worth it to have everything in a separate directory where it will be safe.


<a name="extracting-tree"></a>
## Extracting gene hits and making a tree

You’re doing wonderful. We’re very close. Next, you’re going to want to get your scripts ready. Perform the following commands:

```
$ ln -s $SCRIPTS/get_concatenated_proteins.sh .
$ ln -s $SCRIPTS/get_extended_proteins.sh .
```
Now, link all your contigs dbs here. (This will look messy, but it’s not much of an inconvenience, I promise.)

```
$ ln -s $GENOMES/contigs_dbs/*.db .
$ cp $GENOMES/external-genomes.txt .
```

If you're following the example, your directory will look like this:

```
MyCC_008/
├── Anaerovibrio_lipolyticus.db -> ../../Genomes/contigs_dbs/Anaerovibrio_lipolyticus.db
├── Centipeda_periodontii.db -> ../../Genomes/contigs_dbs/Centipeda_periodontii.db
├── Dendrosporobacter_quercicolus.db -> ../../Genomes/contigs_dbs/Dendrosporobacter_quercicolus.db
├── Megamonas_funiformis.db -> ../../Genomes/contigs_dbs/Megamonas_funiformis.db
├── Megamonas_hypermegale.db -> ../../Genomes/contigs_dbs/Megamonas_hypermegale.db
├── Megamonas_sp.db -> ../../Genomes/contigs_dbs/Megamonas_sp.db
└── MyCC_008
    ├── Grouse_MyCC56_008.db
    ├── Grouse_MyCC56_008.fa
    ├── Grouse_MyCC56_008-fixed.fa
    └── MC_008_Campbellseqs.fa
```

Now, make a symbolic link to the contigs DB in your MyCC_008 directory (or equivalent, if you're not following the example):

```
$ ln -s MyCC_008/Grouse_MyCC56_008.db .
```

And add it to your ```external-genomes.txt```, which should now look like this:

```
name	contigs_db_path
Anaerovibrio_lipolyticus	Anaerovibrio_lipolyticus.db
Centipeda_periodontii	Centipeda_periodontii.db
Dendrosporobacter_quercicolus	Dendrosporobacter_quercicolus.db
Megamonas_funiformis	Megamonas_funiformis.db
Megamonas_hypermegale	Megamonas_hypermegale.db
Megamonas_sp	Megamonas_sp.db
Grouse_MyCC56_008	Grouse_MyCC56_008.db
```

Now, try running:

```
$ bash get_concatenated_proteins.sh
```

This will result in the creation of two files: ```concatenated-nuc-proteins.fa``` (Nucleotide sequences of LSU genes L1-L6) and ```concatenated-proteins.fa``` (Amino acid sequences of the same). Depending on how many genomes you had in external-genomes.txt, this might take a while. If you’re running ```get_extended_proteins.sh```, be prepared to wait if your database is large.

If something is wrong here, check your external-genomes.txt. If you forgot to remove a “db” from one of the fields on the left, or if you have a duplicate name somewhere (which can happen with all the copy-pasting you’ll be doing), you'll get an error. If your files were generated, great! Let’s move on.

Make a directory to run your phylogenetic analysis in. I usually call them First_Tree, Second_Tree, etc. or some variant thereof. Perform the following command:

```
$ mkdir First_Tree
$ mv concatenated* First_Tree/
$ cd First_Tree/
```  

Almost there. Now, I generally like to do my trees using the nucleotide sequences (I just figure it has better phylogenetic signal; I may well be wrong about that, though). Here’s how to do that:

```
$ iqtree-omp -s concatenated-nuc-proteins.fa -bb 1000 -nt AUTO -m TEST
```

This will automatically decide how many threads to use, do ultrafast bootstrap with 1000 bootstrap trees, and test for the best model to use by Aikake and Bayesian information criteria. Now go get a beer or something and come back.

The resulting files should look like this:

```
First_Tree/
├── concatenated-nuc-proteins.fa
├── concatenated-nuc-proteins.fa.bionj
├── concatenated-nuc-proteins.fa.ckp.gz
├── concatenated-nuc-proteins.fa.contree
├── concatenated-nuc-proteins.fa.iqtree
├── concatenated-nuc-proteins.fa.log
├── concatenated-nuc-proteins.fa.mldist
├── concatenated-nuc-proteins.fa.model
├── concatenated-nuc-proteins.fa.splits.nex
├── concatenated-nuc-proteins.fa.treefile
└── concatenated-proteins.fa
```

Great! Now, to visualize this tree, go to [iTOL](http://itol.embl.de). Create an account (you’ll be glad you did) and go to “My Trees” on the top navigation bar. Select “upload tree file” and go to the directory where you just ran iq-tree. Upload the treefile- in our case, “concatenated-nuc-proteins.fa.treefile”.

Here's the tree I get from our example:

![example tree](/assets/images/example-tree.png){:width="1500px"}

As you can see, our genome is very closely related to _Megamonas hypermegale_. That's because (I'm pretty sure) that's what it is. I haven't done any rigorous analysis that might indicate for sure it's the same species, but from this you can get a very high-confidence indication that it's at least part of the genus _Megamonas_ with a well-profiled close relative.

Now, if you see that your genome has a closely related friend in the phylogeny, congratulations! You’re done! Otherwise, look at the most closely related sequences and try to see if you can find any clues as to what your mystery genome might be. Then, go download more genomes from the taxon/taxa of your choice from NCBI, and repeat this whole process again! (I’ve done up to 10 trees in a single directory trying to find out what some stupid bacterium is. I don’t think it has any relatives in the database, unfortunately.)


You now know how to do the whole thing! Congrats!

Please please let me know if you have any questions, suggestions, edits or gripes. Send me a missive: [jwestrob@berkeley.edu](mailto:jwestrob@berkeley.edu).


<a name="references"></a>
## _**REFERENCES**_

- <a href="https://peerj.com/articles/1319/"><font color="blue">Anvi’o: an advanced analysis and visualization platform for ‘omics data</font></a>. A. Murat Eren, et al. PeerJ, 2015 Oct

  - <a href="http://merenlab.org/2017/06/07/phylogenomics/"><font color="blue">An Anvi'o Workflow for Phylogenomics</font></a>

- <a href="https://www.nature.com/articles/s41564-017-0012-7"><font color="blue">Recovery of nearly 8,000 metagenome-assembled genomes substantially expands the tree of life</font></a>. Parks DH, et al. Nat Microbiol 2017 Nov

- D.T. Hoang, O. Chernomor, A. von Haeseler, B.Q. Minh, L.S. Vinh (2018) UFBoot2: Improving the ultrafast bootstrap approximation. Mol. Biol. Evol., 35:518–522. https://doi.org/10.1093/molbev/msx281

- S. Kalyaanamoorthy, B.Q. Minh, T.K.F. Wong, A. von Haeseler, L.S. Jermiin (2017) ModelFinder: Fast model selection for accurate phylogenetic estimates. Nat. Methods, 14:587-589. https://doi.org/10.1038/nmeth.4285

- L.-T. Nguyen, H.A. Schmidt, A. von Haeseler, B.Q. Minh (2015) IQ-TREE: A fast and effective stochastic algorithm for estimating maximum likelihood phylogenies.. Mol. Biol. Evol., 32:268-274. https://doi.org/10.1093/molbev/msu300

- <a href="https://www.nature.com/articles/nature12352"><font color="blue">Insights into the phylogeny and coding potential of microbial dark matter</font></a> Christian Rinke et al. Nature, 2013

- Seeman T, <a href="https://github.com/tseemann/barrnap"><font color="blue">barrnap</font></a>

- <a href="http://www.pnas.org/content/110/14/5540.short"><font color="blue">UGA is an additional glycine codon in uncultured SR1 bacteria from the human microbiota</font></a> James H. Campbell et al., PNAS 2013.
